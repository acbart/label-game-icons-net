import csv
from datetime import datetime
import os
from pydantic import TypeAdapter
from pydantic.dataclasses import dataclass
import dataclasses
from enum import Enum
import logging

logger = logging.getLogger(__name__)

class Relevance(str, Enum):
    low = 'low'
    medium = 'medium'
    high = 'high'
    

def normalize_label(label: str) -> str:
    """
    Normalize a label to be lowercase and have no spaces or punctuation characters.
    
    We want to allow emoji characters in labels, so we don't remove them; we just remove other punctuation.
    """
    normalized = label.lower()
    for char in [' -_;:.,()[]{}<>$%&@#^*+=|/\\!"\'`~']:
        normalized = normalized.replace(char, '')
    return normalized


@dataclass
class Label:
    # The name of the icon for this label
    icon: str
    # The actual label text
    text: str
    # How relevant this label is to the icon
    relevance: Relevance
    # The language code for this label
    language: str
    # If a human authored this label, this is their github id
    author: str
    # If a human reviewed this label, this is their github id
    reviewer: str
    # Whether this label is "valid" (aka actually relevant) or not; some labels can be deprecated
    valid: str
    # Whether or not a human authored this label, or if it was generated by a machine
    human_authored: bool
    # Whether or not a human reviewed this label, or if it was reviewed by a machine
    # Machine reviews are always replaced by a human review
    human_reviewed: bool
    # The ID of the prompt that generated this label, if it's a machine-generated label
    prompt_id: str
    # The unique ID of the GPT run that generated this label, if it's a machine-generated label
    gpt_run_id: str
    execution_id: str
    # The GPT Model used
    gpt_model: str
    # The datetime this label was generated in ISO
    when_authored: str
    # The datetime this label was reviewed in ISO
    when_reviewed: str
    # The number of times this label has been generated again (so it's always at least one)
    count: int
    
    
    @classmethod
    def from_gpt(cls, icon_name: str, text: str, relevance: str,
                 author: str, prompt_id: str, execution_id: str, gpt_model: str,
                 gpt_run_id: str):
        return cls(
            icon=icon_name,
            text=text,
            relevance=Relevance(relevance),
            language="en",
            author=author,
            reviewer="",
            valid='',
            human_authored=False,
            human_reviewed=False,
            prompt_id=prompt_id,
            execution_id=execution_id,
            gpt_model=gpt_model,
            gpt_run_id=gpt_run_id,
            when_authored=datetime.now().isoformat(),
            when_reviewed="",
            count=1,
        )
    
@dataclasses.dataclass
class LabelError:
    row: int
    error: Exception
    label_file: "LabelFile"

RELEVANCE_ORDER = {
    Relevance.low: 0,
    Relevance.medium: 1,
    Relevance.high: 2,
}

@dataclasses.dataclass
class LabelFile:
    icon: str
    path: str
    labels: list[Label] = dataclasses.field(default_factory=list)
    errors: list[LabelError] = dataclasses.field(default_factory=list)
    LABEL_PATH: str = 'labels/{icon}.csv'
    
    def __init__(self, icon: str):
        self.icon = icon
        self.path = self.LABEL_PATH.format(icon=icon)
        self.labels = []
        self.errors = []
        self.load()
        
    def create_file(self):
        # Create directory if it doesn't exist
        os.makedirs(os.path.dirname(self.path), exist_ok=True)
        with open(self.path, 'w', encoding='utf-8', newline="") as f:
            writer = csv.DictWriter(f, fieldnames=Label.__dataclass_fields__.keys())
            writer.writeheader()
    
    def load(self):
        if not os.path.exists(self.path):
            self.create_file()
        with open(self.path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row_id, row in enumerate(reader):
                try:
                    label = Label(**row)
                except Exception as e:
                    self.errors.append(LabelError(row=row_id, error=e, label_file=self))
                    logger.error(f"Error loading label from {self.path} at row {row_id}: {e}")
                    continue
                self.labels.append(label)
    
    def increase_count_if_exists(self, label: str):
        for existing_label in self.labels:
            if existing_label.text == label:
                existing_label.count += 1
                return True
        return False

    def save(self):
        self.clean_up()
        with open(self.path, 'w', encoding='utf-8', newline="") as f:
            writer = csv.DictWriter(f, fieldnames=Label.__dataclass_fields__.keys())
            writer.writeheader()
            for label in self.labels:
                writer.writerow(dataclasses.asdict(label))
    
    def clean_up(self):
        """
        Sorts the existing labels, putting invalid ones at the bottom, and sorting them by relevance
        and date.
        """
        self.labels = sorted(self.labels, 
                             key=lambda x: (x.valid, -RELEVANCE_ORDER[x.relevance], x.text))
        
    def add_label(self, label: Label):
        self.labels.append(label)
    
    def add_labels(self, labels: list[Label]):
        self.labels.extend(labels)
    
